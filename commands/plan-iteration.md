# Interview-based iteration planning with embedded standards

## Environment Context

**NOTE**: Workflow environment variables are already loaded:
- `$WORKFLOW_PROJECTS` - Obsidian projects directory 
- `$WORKFLOW_HOME` - Workflow system location
- These are available for direct use in file paths

## ‚ö†Ô∏è CRITICAL: INTERVIEW FIRST - NO ARTIFACTS UNTIL APPROVED ‚ö†Ô∏è

**üõë STOP AFTER INTERVIEW. DO NOT GENERATE ARTIFACTS.**  
**üõë ASK QUESTIONS ONE AT A TIME - BUILD ON ANSWERS**  
**üõë ALWAYS END WITH: "Ready to generate ITERATION.md with embedded context?"**  
**üõë WAIT FOR EXPLICIT APPROVAL BEFORE CREATING ITERATION.MD**

## ‚ö†Ô∏è CRITICAL: STANDARDS MUST BE LOADED AND EMBEDDED ‚ö†Ô∏è

**üõë NO ITERATION.MD WITHOUT STANDARDS VERIFICATION**  
**üõë LIST EVERY STANDARDS FILE PATH READ**  
**üõë QUOTE SPECIFIC PATTERNS FROM EACH STANDARD**  
**üõë EMBED ALL CONTEXT - NO EXTERNAL REFERENCES**

## ‚ö†Ô∏è CRITICAL: PRESERVE INTERVIEW GOLD ‚ö†Ô∏è

**üõë CAPTURE CONCRETE DETAILS DISCOVERED IN INTERVIEW**  
**üõë NO GENERIC TASK DESCRIPTIONS**  
**üõë ACTUAL CODE EXAMPLES AND DATA STRUCTURES**  
**üõë ONE SMOKE TEST PER TASK - NO TDD THEATER**

## ‚ö†Ô∏è CRITICAL: RESEARCH SPIKE REQUIREMENTS ‚ö†Ô∏è

**üõë RESEARCH SPIKES MUST PRODUCE WORKING CODE:**

- Time-boxed exploration (1-2 hours max)
- Concrete working code artifact (not just documentation)
- Throwaway code is acceptable for learning
- Must test actual integration/approach through building
- Decision criteria based on what actually works in practice

## ‚ö†Ô∏è CRITICAL: THINK ‚ö†Ô∏è

### PHASE 0: PREPARATION

- READ EVERYTHING 3 TIMES BEFORE DOING ANYTHING
- WHEN YOU MAKE A PLAN - REVIEW IT INTERNALLY FIRST TO CHECK FOR OMISSIONS, OVERSIGHTS AND MISTAKES
- ENSURE YOU CAPTURE ALL TECHNOLOGY MENTIONED IN IDEA.md - REVIEW IT 3 TIMES

## MANDATORY EXECUTION SEQUENCE - NO SKIPPING

### PHASE 1: FOUNDATION LOADING (REQUIRED)

**CHECKPOINT 1: Load All Foundation Context**

```
REQUIRED: Read and acknowledge ALL foundation files:
- .workflow/resources/DESIGN_PRINCIPLES.md
- .workflow/resources/IMPLEMENTATION_GUIDELINES.md
- .workflow/artifacts/IDEA.md (Core vision, problem, solution, and features)
- .workflow/artifacts/APP_CONTEXT.md (if exists) - Current system understanding
- .workflow/artifacts/QUESTIONS.md (if exists) - Open questions to address
- $WORKFLOW_PROJECTS/[projectname]/01-backlog.md (if exists)
- $WORKFLOW_PROJECTS/[projectname]/designs/ (if exists) - Design artifacts and decisions
- CLAUDE.md (if exists) - Development context and patterns

VERIFICATION: State "Foundation context loaded" and summarize the composition-first approach
```

**CHECKPOINT 2: System State Analysis**

```
REQUIRED: Analyze current system architecture and existing components:
- SCAN .workflow/archives/ directory for completed iterations
- IDENTIFY what services/APIs/components exist from previous work
- ASSESS current system architecture and data flows
- ANALYZE existing interfaces and integration points
- UNDERSTAND what infrastructure is already running

SYSTEM INTEGRATION ANALYSIS:
- What services were built in previous iterations?
- What APIs/endpoints are available for integration?
- What databases/storage systems exist?
- What configuration/deployment infrastructure exists?
- How do existing components communicate with each other?

VERIFICATION: Map existing system components and their integration points
```

**CHECKPOINT 3: Tech Stack Detection**

```
REQUIRED: Analyze IDEA.md and detect ALL technologies mentioned
- Scan for: languages, frameworks, databases, deployment tools
- List EVERY technology found
- Identify primary stack (e.g., "Python web API with PostgreSQL")

!!CRITICAL!! 
- READ IDEA.md INTERNALLY 10 times to identify technologies you may have missed!
- DO NOT GREP!!

VERIFICATION: List all detected technologies explicitly
```

**CHECKPOINT 4: Standards Loading (MANDATORY)**

```
REQUIRED: For EACH detected technology, read corresponding standards:
- ~/.claudex/standards/claudex-python.md (if Python detected)
- [Continue for ALL detected technologies]

NOTE: IT *REALLY* is ~/.claudex/standards/ and NOT ~/.workflow/standards/

VERIFICATION GATE: You MUST list:
1. Every standards file path read
2. Key patterns from each standard
3. Version requirements from each standard
4. Quality gates from each standard

FAILURE MODE: If you cannot list specific patterns from each standard, you MUST re-read the files
```

### PHASE 2: SCOPE INTERVIEW (REQUIRED)

**CHECKPOINT 5: Integration Architecture Interview**

```
REQUIRED: Understand how new iteration integrates with existing system:

CONCRETE DISCOVERY QUESTIONS:
- "What exact APIs/endpoints will this connect to?"
- "Show me the WebSocket message format this will receive"
- "What database tables/queries does this need?"
- "What's the exact curl command to test this?"

CAPTURE DURING INTERVIEW:
## Interview Discoveries - Integration
- Existing endpoints: {exact paths and methods}
- Message formats: {real JSON examples}
- Database needs: {specific tables and queries}
- Test commands: {exact curl/requests}

VERIFICATION: Document all integration points with concrete examples
```

**CHECKPOINT 6: Feature Implementation Interview**

```
REQUIRED: Extract concrete implementation details:

CONCRETE DISCOVERY QUESTIONS:
- "What specific user action triggers this feature?"
- "What exact data do we receive/send?" (get JSON examples)
- "Show me what success looks like" (get exact output)
- "What's the simplest implementation that works?"
- "What's the ONE test that proves this works?"

CAPTURE DURING INTERVIEW:
## Interview Discoveries - Implementation
- User triggers: {exact button clicks/commands}
- Data structures: {real JSON/models from discussion}
- Success criteria: {exact expected output}
- Core logic: {pseudocode or approach}
- Test scenario: {the one integration test that matters}

VERIFICATION: Have concrete examples for every feature
```

**CHECKPOINT 7: Task Decomposition Interview**

```
REQUIRED: Break features into <4 hour concrete tasks:

TASK DISCOVERY QUESTIONS:
- "What's the first working piece we can ship?"
- "What files need to be created/modified?"
- "Are there any unknowns requiring research spikes?"
- "What's the critical path of dependencies?"

TASK TYPE IDENTIFICATION:
- Implementation tasks: Known approach, clear patterns
- Research spikes: Time-boxed exploration (1-2 hours max)
- Integration tasks: Connect components to existing system
- Wiring tasks: Configuration and orchestration

VERIFICATION: Each task has single responsibility and clear deliverable
```

### PHASE 3: MANDATORY INTERVIEW COMPLETION

**‚ö†Ô∏è CRITICAL: INTERVIEW FIRST - NO ARTIFACTS UNTIL APPROVED ‚ö†Ô∏è**

```
MANDATORY CLOSING STATEMENT:
=====================================
INTERVIEW COMPLETE - NO ARTIFACTS GENERATED
=====================================

Tech Stack Detected: [list with versions]
Standards Loaded:
- Python: [specific patterns loaded]
- React: [specific patterns loaded]
- [etc for each tech]

System Integration Mapped:
- Existing APIs: [list]
- Database tables: [list]
- Message formats: [list]

Interview Discoveries Captured:
- User workflows: [key insights]
- Data structures: [key formats]
- Integration points: [key connections]
- Test scenarios: [key validations]

Proposed Tasks: [count] tasks
- Implementation: [count]
- Research Spikes: [count]
- Integration: [count]
- Wiring: [count]

Ready to generate ITERATION.md with embedded context?

Please respond with YES or NO.
```

**üõë STOP HERE - WAIT FOR APPROVAL**

### PHASE 4: ITERATION GENERATION (AFTER APPROVAL)

**CHECKPOINT 8: Update Feature Status in IDEA.md**

```
REQUIRED: Update IDEA.md with iteration progress:
- DETERMINE next iteration number from .workflow/archives/
- MARK selected features as üîÑ In Progress (iteration-N)
- UPDATE .workflow/artifacts/IDEA.md with new feature statuses

VERIFICATION: Confirm feature status updates applied
```

**CHECKPOINT 9: Generate ITERATION.md Using Template**

```
REQUIRED: Create ITERATION.md preserving ALL interview discoveries:
- LOAD .workflow/templates/ITERATION_TEMPLATE.md
- POPULATE with concrete details from interview discoveries
- EMBED all loaded tech standards directly
- PRESERVE exact data structures, commands, examples
- CREATE tasks with specific implementation details

MANDATORY SECTIONS TO POPULATE:
1. Working Software Goal (what users can DO)
2. Context from Previous Iterations (built, current, infrastructure)
3. Tech Stack & Embedded Standards (paste actual patterns)
4. Integration Architecture (exact APIs and data flows)
5. Tasks with ALL interview details preserved
6. Quality Gates (from standards)
7. Success Demo (exact commands)

VERIFICATION: Every interview discovery appears in final ITERATION.md
```

**CHECKPOINT 10: Task Construction with Interview Details**

```
REQUIRED: Transform interview discoveries into concrete tasks:

FOR EACH TASK INCLUDE:
- Type, dependencies, time estimate
- Exact files to create/modify (from interview)
- Real code structure (from interview)
- Actual data examples (from interview)
- Specific integration points (from interview)
- One concrete smoke test (from interview)
- Exact success verification commands

EXAMPLE:
### 1. JWT Login Endpoint üìã Planned

**Type**: Implementation Task
**Depends on**: None
**Estimated time**: 2 hours

**What to build**: POST /auth/login that returns JWT token

**Key files**:
- backend/api/auth.py - FastAPI login endpoint
- backend/services/auth_service.py - JWT generation

**Core functionality**:
[EXACT code structure from interview]

**Data structures** (from interview):
[EXACT JSON examples from interview]

**Integration points**:
- Database: users table with bcrypt passwords
- Returns: JWT token for Authorization header

**One smoke test**:
[EXACT test from interview discussion]

**Success verification**:
[EXACT curl command from interview]
```

**CHECKPOINT 11: Embed Standards in Context**

```
REQUIRED: Paste actual standards patterns in Tech Stack section:

## Tech Stack & Embedded Standards

### Python Backend (FastAPI)
[PASTE actual patterns from ~/.claudex/standards/python/modern-python.md]
- **Package Management**: Use `uv` exclusively (NOT pip)
- **Async patterns**: All endpoints use `async def`
- **Testing**: pytest with real PostgreSQL
[etc - actual content from standards file]

### React Frontend
[PASTE actual patterns from ~/.claudex/standards/react/modern-react.md]
[etc for each technology]

VERIFICATION: Standards are embedded, not referenced
```

**CHECKPOINT 12: Final Validation**

```
VERIFICATION GATE: Before finalizing ITERATION.md, confirm:
- [ ] All interview discoveries preserved in tasks
- [ ] Standards embedded with specific patterns
- [ ] Each task has concrete implementation details
- [ ] Integration points include exact formats
- [ ] One smoke test per task defined
- [ ] Success commands are exact (not generic)
- [ ] Task types and dependencies clear
- [ ] Time estimates realistic (<4 hours)

FAILURE MODE: If missing interview details or using generic descriptions, REGENERATE
```

### PHASE 5: COMPLETION STATEMENT

```
=====================================
ITERATION PLANNED WITH INTERVIEW GOLD PRESERVED
=====================================

‚úÖ [X] concrete tasks with implementation details
‚úÖ [Y] interview discoveries preserved  
‚úÖ [Z] standards embedded with patterns
‚úÖ One smoke test per task
‚úÖ Exact success verification commands
‚úÖ All integration points mapped

No generic descriptions - everything concrete from interview.

Ready for implementation with /plan-task 1
```

## ENFORCEMENT MECHANISMS

### Interview Preservation Gates

- Must capture concrete examples during interview
- Must preserve exact data formats and commands
- Must include real code snippets discussed
- No generic task descriptions allowed

### Standards Compliance Gates

- Must load ALL detected tech standards
- Must quote specific patterns from each
- Must embed standards in ITERATION.md
- No external references

### Task Quality Gates

- Each task must have single responsibility
- Must include exact implementation details
- Must have one concrete smoke test
- Must be completable in <4 hours

## FAILURE MODES & RECOVERY

**If interview too vague:** Ask more concrete questions  
**If standards not loaded:** STOP and read required files  
**If tasks generic:** Re-read interview discoveries and add specifics  
**If no concrete examples:** Request exact commands/data from user